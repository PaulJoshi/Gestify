{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collect Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import uuid\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = 'Tensorflow/workspace/images/collectedimages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['hello', 'thanks', 'iloveyou', 'yes', 'no']\n",
    "number_imgs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Tensorflow\\workspace\\images\\collectedimages\\hello already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for hello\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n",
      "Collecting image 10\n",
      "Collecting image 11\n",
      "Collecting image 12\n",
      "Collecting image 13\n",
      "Collecting image 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Tensorflow\\workspace\\images\\collectedimages\\thanks already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for thanks\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting image 5\n",
      "Collecting image 6\n",
      "Collecting image 7\n",
      "Collecting image 8\n",
      "Collecting image 9\n",
      "Collecting image 10\n",
      "Collecting image 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Tensorflow\\workspace\\images\\collectedimages\\iloveyou already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for iloveyou\n",
      "Collecting image 0\n",
      "Collecting images for yes\n",
      "Collecting image 0\n",
      "Collecting images for no\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Paul Joshi\\Desktop\\sign-language-recognition\\RealTimeSignLanguageDetectionWebApp\\Image Collection.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Paul%20Joshi/Desktop/sign-language-recognition/RealTimeSignLanguageDetectionWebApp/Image%20Collection.ipynb#ch0000004?line=2'>3</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Paul%20Joshi/Desktop/sign-language-recognition/RealTimeSignLanguageDetectionWebApp/Image%20Collection.ipynb#ch0000004?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCollecting images for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(label))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Paul%20Joshi/Desktop/sign-language-recognition/RealTimeSignLanguageDetectionWebApp/Image%20Collection.ipynb#ch0000004?line=4'>5</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Paul%20Joshi/Desktop/sign-language-recognition/RealTimeSignLanguageDetectionWebApp/Image%20Collection.ipynb#ch0000004?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m imgnum \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_imgs): \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Paul%20Joshi/Desktop/sign-language-recognition/RealTimeSignLanguageDetectionWebApp/Image%20Collection.ipynb#ch0000004?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCollecting image \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(imgnum))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    !mkdir {'Tensorflow\\workspace\\images\\collectedimages\\\\' + label}\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs): \n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH, label, label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e0a928c10214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
